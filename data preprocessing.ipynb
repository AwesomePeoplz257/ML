{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset, Audio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "file_names = []\n",
    "transcriptions = []\n",
    "for speaker in range(1, 11):\n",
    "    finished_reading = False\n",
    "    if speaker != 10:\n",
    "        f = open(f\"C:\\\\Users\\\\hojon\\\\OneDrive\\\\Desktop\\\\IRS Data\\\\TIL\\\\SCRIPT\\\\2000{speaker}0.txt\", \"r\")\n",
    "    else:\n",
    "        f = open(f\"C:\\\\Users\\\\hojon\\\\OneDrive\\\\Desktop\\\\IRS Data\\\\TIL\\\\SCRIPT\\\\200{speaker}0.txt\", \"r\")\n",
    "\n",
    "    while finished_reading != True:\n",
    "        info = f.readline().split(\"\\t\")\n",
    "        if info == ['']:\n",
    "            finished_reading = True\n",
    "        else:\n",
    "            id, _ = info\n",
    "        id = id[id.index('2'):]\n",
    "        transcription = f.readline()\n",
    "        file_names.append(f'C:\\\\Users\\\\hojon\\\\OneDrive\\\\Desktop\\\\IRS Data\\\\TIL\\\\WAVE\\\\{id}.wav')\n",
    "        transcriptions.append(transcription.strip())\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              file_name  \\\n",
      "0     C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "1     C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "2     C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "3     C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "4     C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "...                                                 ...   \n",
      "3533  C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "3534  C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "3535  C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "3536  C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "3537  C:\\Users\\hojon\\OneDrive\\Desktop\\IRS Data\\TIL\\W...   \n",
      "\n",
      "                                          transcription  \n",
      "0         there were barrels of wine in the huge cellar  \n",
      "1     she won a car because she was the twelfth pers...  \n",
      "2     as they walked back they were shocked to see a...  \n",
      "3             heavy rains caused a flood in the village  \n",
      "4                               he gulped down his beer  \n",
      "...                                                 ...  \n",
      "3533  indeed schools are exposing students to more c...  \n",
      "3534  every few months he would flee from the home a...  \n",
      "3535  it sets out the manpower and skills developmen...  \n",
      "3536  an amount given back to taxpayers that reduces...  \n",
      "3537                                                     \n",
      "\n",
      "[3538 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "d = {\"file_name\": file_names, \"transcription\": transcriptions}\n",
    "df = pd.DataFrame(data = d)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# df.to_csv(\"metadata.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "audio_dataset = Dataset.from_dict({\"audio\": file_names, \"transcription\": transcriptions}).cast_column(\"audio\", Audio())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['audio', 'transcription'],\n    num_rows: 3538\n})"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'path': 'C:\\\\Users\\\\hojon\\\\OneDrive\\\\Desktop\\\\IRS Data\\\\TIL\\\\WAVE\\\\200040041.wav',\n 'array': array([0.0010376 , 0.00137329, 0.00210571, ..., 0.0039978 , 0.00283813,\n        0.00231934]),\n 'sampling_rate': 16000}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dataset[1000]['audio']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1769 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f49d0f06bd1546dba6d2a0be7cff67dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Pushing dataset shards to the dataset hub:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a999b266678f40e49370fdcb061eae53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bad2b5dd93d04e13b5032515d6bc0b39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "636c73cbff024d94b61267c5fedd1afa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1769 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14aee7d8e1d74ae98a8c51eca142979c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c6a3c8c51454145ac525c5fad1ae21c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e77579c671248c49c2d636816044379"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_dataset.push_to_hub(\"casual/trainaudio\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/420 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6597f837d3145ce8b40c046cae816cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to C:/Users/hojon/.cache/huggingface/datasets/casual___parquet/casual--national_speech_corpusv2-96a77f2d17c10138/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f38972bc52be4201ad5e9e4ef3737109"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/267M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "269aa0bde3f241e9a4192eca08b12a79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/290M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ce80b8a50c6489eadff8fc6be1ff3b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5ed70f52b9a407ba224e5e10d5e5220"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/3538 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e0e22d10c9f45f2a980ee9cb9dc1fc8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:/Users/hojon/.cache/huggingface/datasets/casual___parquet/casual--national_speech_corpusv2-96a77f2d17c10138/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81e214245af948b69cdeb5606aee3cbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['audio', 'transcription'],\n        num_rows: 3538\n    })\n})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = load_dataset(\"casual/national_speech_corpusv2\")\n",
    "new_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'path': '200010001.wav',\n 'array': array([-0.01141357, -0.00149536, -0.0017395 , ..., -0.00363159,\n        -0.00271606, -0.00195312]),\n 'sampling_rate': 16000}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['train'][0]['audio']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "competition code preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:\\\\Users\\\\hojon\\\\OneDrive\\\\Desktop\\\\IRS Data\\\\TIL\\\\comps data\\\\Train.csv\")\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\hojon\\\\OneDrive\\\\Desktop\\\\IRS Data\\\\TIL\\\\comps data\\\\Test_Novice_19May.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "              path\n0  evalb_00001.wav\n1  evalb_00002.wav\n2  evalb_00003.wav\n3  evalb_00004.wav\n4  evalb_00005.wav",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>evalb_00001.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>evalb_00002.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>evalb_00003.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>evalb_00004.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>evalb_00005.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # converting annotations to lowercase\n",
    "    df['annotation'] = [annotation.lower() for annotation in df['annotation']]\n",
    "\n",
    "    # changing the numbers (letter form) to digits\n",
    "    temp = []\n",
    "    word2num = {'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'seven': 7, 'eight': 8, 'nine': 9,\n",
    "                'ten': 10, 'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14, 'fifteen': 15, 'sixteen': 16,\n",
    "                'seventeen': 17, 'eighteen': 18, 'nineteen': 19, 'twenty': 20, 'thirty': 30, 'forty': 40, 'fifty': 50,\n",
    "                'sixty': 60, 'seventy': 70, 'eighty': 80, 'ninety': 90, 'zero': 0}\n",
    "    for annotation in df['annotation']:\n",
    "        sentence_added = False\n",
    "        for word in word2num.keys():\n",
    "            if word in annotation and sentence_added == False:\n",
    "                index = annotation.index(word)\n",
    "                new_annotation = annotation[:index] + str(word2num[word]) + annotation[index + len(word):]\n",
    "                temp.append(new_annotation)\n",
    "                sentence_added = True\n",
    "\n",
    "        if sentence_added == False:\n",
    "            temp.append(annotation)\n",
    "\n",
    "    df['annotation'] = temp\n",
    "\n",
    "    # making the first letter uppercase, add full stop to the back\n",
    "    temp = []\n",
    "    for annotation in df['annotation']:\n",
    "        new_annotation = annotation[0].upper() + annotation[1:] + \".\"\n",
    "        temp.append(new_annotation)\n",
    "    df['annotation'] = temp\n",
    "\n",
    "    # changing the filepaths\n",
    "    temp = []\n",
    "    for path in df['path']:\n",
    "        if type == 'train':\n",
    "            new_path = \"C:\\\\Users\\\\hojon\\\\OneDrive\\\\Desktop\\\\IRS Data\\\\TIL\\\\comps data\\\\Train\\\\Train\\\\audio\\\\\" + path[6:]\n",
    "\n",
    "        temp.append(new_path)\n",
    "    df['path'] = temp\n",
    "\n",
    "    audio_dataset = Dataset.from_dict({\"audio\": df['path'], \"annotation\": df['annotation']}).cast_column(\"audio\", Audio())\n",
    "\n",
    "    return audio_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'annotation'],\n",
      "    num_rows: 3750\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "audio_dataset = preprocess_data(df)\n",
    "print(audio_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "'She scored 9 for the quiz.'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dataset[0]['annotation']"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
